{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jithendra1798/ML-CS-GY-6923-B/blob/main/09_ml_cs_gy_6923_b_lab_06_rnns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 6: RNNs\n",
        "\n",
        "## Part 1: Manual RNN\n",
        "\n",
        "In this first part of the lab, you will need to implement the components of the RNN manually and check your implementation against pytorch. The goal is to get a good low-level understanding of what an RNN is actually doing."
      ],
      "metadata": {
        "id": "5LAcFLSfW2vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rzo1laXyUGrX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, complete the implementation of the embedding layer below."
      ],
      "metadata": {
        "id": "7S9TaBdsW1wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ManualEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    Manual implementation of an embedding layer.\n",
        "\n",
        "    An embedding layer is essentially a lookup table that maps integer indices\n",
        "    to dense vectors. Mathematically, it's equivalent to one-hot encoding\n",
        "    followed by a matrix multiplication.\n",
        "\n",
        "    Args:\n",
        "        vocab_size: Number of unique tokens in vocabulary\n",
        "        embed_dim: Dimension of embedding vectors\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.weight = nn.Parameter(torch.randn(vocab_size, embed_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Integer tensor of shape (batch_size, seq_length)\n",
        "\n",
        "        Returns:\n",
        "            embedded: Tensor of shape (batch_size, seq_length, embed_dim)\n",
        "\n",
        "        TODO: Implement the forward pass\n",
        "        Hint: You can use indexing (self.weight[x]) or torch.index_select\n",
        "        \"\"\"\n",
        "        # Your implementation here\n",
        "        embedded = self.weight[x]\n",
        "        return embedded"
      ],
      "metadata": {
        "id": "z92JQN_tUn35"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, complete the implementation of an RNN cell below. The cell is a single transition in an RNN, see docstring for details."
      ],
      "metadata": {
        "id": "RsO7-mD9YIx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ManualRNNCell(nn.Module):\n",
        "    \"\"\"\n",
        "    Manual implementation of a single RNN cell.\n",
        "\n",
        "    A vanilla RNN cell computes:\n",
        "        h_t = tanh(W_ih @ x_t + b_ih + W_hh @ h_{t-1} + b_hh)\n",
        "\n",
        "    where:\n",
        "        x_t is the input at time t\n",
        "        h_t is the hidden state at time t\n",
        "        W_ih is the input-to-hidden weight matrix\n",
        "        W_hh is the hidden-to-hidden weight matrix\n",
        "        b_ih, b_hh are bias vectors\n",
        "\n",
        "    Args:\n",
        "        input_size: Dimension of input features\n",
        "        hidden_size: Dimension of hidden state\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.W_ih = nn.Parameter(torch.randn(hidden_size, input_size))\n",
        "        self.b_ih = nn.Parameter(torch.randn(hidden_size))\n",
        "        self.W_hh = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
        "        self.b_hh = nn.Parameter(torch.randn(hidden_size))\n",
        "\n",
        "        # Initialize weights (Xavier initialization)\n",
        "        nn.init.xavier_uniform_(self.W_ih)\n",
        "        nn.init.xavier_uniform_(self.W_hh)\n",
        "        nn.init.zeros_(self.b_ih)\n",
        "        nn.init.zeros_(self.b_hh)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch_size, input_size)\n",
        "            hidden: Previous hidden state of shape (batch_size, hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            new_hidden: New hidden state of shape (batch_size, hidden_size)\n",
        "\n",
        "        TODO: Implement the RNN cell computation\n",
        "        Hint: Use torch.matmul or @ for matrix multiplication\n",
        "        Hint: Use torch.tanh for activation\n",
        "        \"\"\"\n",
        "        # Your implementation here\n",
        "        # h_t = tanh(W_ih @ x_t + b_ih + W_hh @ h_{t-1} + b_hh)\n",
        "\n",
        "        Wx = x @ self.W_ih.T + self.b_ih\n",
        "\n",
        "        Wh = hidden @ self.W_hh.T + self.b_hh\n",
        "\n",
        "        new_hidden = torch.tanh(Wx + Wh)\n",
        "        return new_hidden\n"
      ],
      "metadata": {
        "id": "EPy_3fFnVC0b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will use our `ManualRNNCell` class to make a full RNN. Complete the code below. Note that the code should work with multiple hidden layers."
      ],
      "metadata": {
        "id": "v3QgMdYmYU1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ManualRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Manual implementation of a multi-layer RNN.\n",
        "\n",
        "    This processes a sequence by applying RNN cells across time steps\n",
        "    and optionally across multiple layers.\n",
        "\n",
        "    Args:\n",
        "        input_size: Dimension of input features\n",
        "        hidden_size: Dimension of hidden state\n",
        "        num_layers: Number of stacked RNN layers\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.cells = nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            input_dim = input_size if layer == 0 else hidden_size\n",
        "            self.cells.append(ManualRNNCell(input_dim, hidden_size))\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch_size, seq_length, input_size)\n",
        "            hidden: Initial hidden state of shape (num_layers, batch_size, hidden_size)\n",
        "                   If None, initialize with zeros\n",
        "\n",
        "        Returns:\n",
        "            output: Output tensor of shape (batch_size, seq_length, hidden_size)\n",
        "            hidden: Final hidden state of shape (num_layers, batch_size, hidden_size)\n",
        "\n",
        "        TODO: Implement the forward pass\n",
        "        Hint: Loop over sequence length (time steps)\n",
        "        Hint: Loop over layers\n",
        "        Hint: Each layer's output becomes the next layer's input\n",
        "        \"\"\"\n",
        "        batch_size, seq_length, _ = x.shape\n",
        "\n",
        "        # Initialize hidden state if not provided\n",
        "        if hidden is None:\n",
        "            hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size,\n",
        "                               device=x.device, dtype=x.dtype)\n",
        "\n",
        "        # Clone hidden state to avoid modifying the input tensor\n",
        "        hidden = hidden.clone()\n",
        "\n",
        "        # Store outputs for each time step\n",
        "        outputs = []\n",
        "\n",
        "        # Process sequence\n",
        "        for t in range(seq_length):\n",
        "            # Get input at time t\n",
        "            input_t = x[:, t, :]  # (batch_size, input_size)\n",
        "\n",
        "            # Process through each layer\n",
        "            for layer_idx in range(self.num_layers):\n",
        "\n",
        "                # 1. Get hidden state for this layer\n",
        "                h_prev = hidden[layer_idx]\n",
        "\n",
        "                # 2. Apply RNN cell\n",
        "                h_new = self.cells[layer_idx](input_t, h_prev)\n",
        "\n",
        "                # 3. Update hidden state\n",
        "                hidden[layer_idx] = h_new\n",
        "\n",
        "                # 4. Output of this layer becomes input to next layer\n",
        "                input_t = h_new\n",
        "\n",
        "            outputs.append(input_t.unsqueeze(1))\n",
        "\n",
        "        output = torch.cat(outputs, dim=1)  # (batch_size, seq_length, hidden_size)\n",
        "\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "Q4otHnKbVD7J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can put everything together to make a ful RNN. Run the code and the tests below, and make sure the tests pass."
      ],
      "metadata": {
        "id": "aZ3L86iNY5v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_layers=2):\n",
        "        \"\"\"\n",
        "        Character-level RNN for language modeling\n",
        "\n",
        "        Args:\n",
        "            vocab_size: Number of unique characters in vocabulary\n",
        "            embed_dim: Dimension of character embeddings\n",
        "            hidden_dim: Dimension of RNN hidden state\n",
        "            num_layers: Number of stacked RNN layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Character embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        # RNN layer (you can swap with LSTM or GRU)\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=embed_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,  # Input shape: (batch, seq, feature)\n",
        "            dropout=0\n",
        "        )\n",
        "\n",
        "        # Output layer to predict next character\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch_size, seq_length)\n",
        "            hidden: Optional hidden state from previous step\n",
        "\n",
        "        Returns:\n",
        "            logits: Predicted logits of shape (batch_size, seq_length, vocab_size)\n",
        "            hidden: Hidden state for next step\n",
        "        \"\"\"\n",
        "        # Embed characters: (batch, seq) -> (batch, seq, embed_dim)\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Pass through RNN: (batch, seq, embed_dim) -> (batch, seq, hidden_dim)\n",
        "        rnn_out, hidden = self.rnn(embedded, hidden)\n",
        "\n",
        "        # Project to vocabulary: (batch, seq, hidden_dim) -> (batch, seq, vocab_size)\n",
        "        logits = self.fc(rnn_out)\n",
        "\n",
        "        return logits, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size, device='cpu'):\n",
        "        \"\"\"Initialize hidden state with zeros\"\"\"\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "\n",
        "\n",
        "class ManualCharRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Character-level RNN using manual implementations of all layers.\n",
        "\n",
        "    This should be functionally equivalent to the standard CharRNN,\n",
        "    but using your custom Embedding, RNN, and Linear layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # TODO: Use your manual implementations\n",
        "        self.embedding = ManualEmbedding(vocab_size, embed_dim)\n",
        "        self.rnn = ManualRNN(embed_dim, hidden_dim, num_layers)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch_size, seq_length)\n",
        "            hidden: Optional hidden state from previous step\n",
        "\n",
        "        Returns:\n",
        "            logits: Predicted logits of shape (batch_size, seq_length, vocab_size)\n",
        "            hidden: Hidden state for next step\n",
        "        \"\"\"\n",
        "        # TODO: Implement forward pass using your custom layers\n",
        "        embedded = self.embedding(x)\n",
        "        rnn_out, hidden = self.rnn(embedded, hidden)\n",
        "        logits = self.fc(rnn_out)\n",
        "        return logits, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size, device='cpu'):\n",
        "        \"\"\"Initialize hidden state with zeros\"\"\"\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)"
      ],
      "metadata": {
        "id": "qW1pbnj0VgLT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_embedding():\n",
        "    \"\"\"Test the manual embedding layer\"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Testing Embedding Layer\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    vocab_size, embed_dim = 10, 8\n",
        "    batch_size, seq_len = 2, 5\n",
        "\n",
        "    # Create both versions\n",
        "    manual_emb = ManualEmbedding(vocab_size, embed_dim)\n",
        "    pytorch_emb = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "    # Copy weights to make them identical\n",
        "    pytorch_emb.weight.data = manual_emb.weight.data.clone()\n",
        "\n",
        "    # Test input\n",
        "    x = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
        "\n",
        "    # Forward pass\n",
        "    manual_out = manual_emb(x)\n",
        "    pytorch_out = pytorch_emb(x)\n",
        "    max_diff = (manual_out - pytorch_out).abs().max().item()\n",
        "\n",
        "    # Compare\n",
        "    print(f\"Input shape: {x.shape}\")\n",
        "    print(f\"Output shape: {manual_out.shape}\")\n",
        "    print(f\"Max difference: {max_diff:.10f}\")\n",
        "    if max_diff > 1e-6:\n",
        "        print(f\"✗ Embedding layer test failed!\")\n",
        "    else:\n",
        "      print(f\"✓ Embedding layer test passed!\\n\")\n",
        "\n",
        "\n",
        "def test_rnn_cell():\n",
        "    \"\"\"Test the manual RNN cell\"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Testing RNN Cell\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    input_size, hidden_size = 10, 16\n",
        "    batch_size = 2\n",
        "\n",
        "    # Create manual cell\n",
        "    manual_cell = ManualRNNCell(input_size, hidden_size)\n",
        "    pytorch_cell = nn.RNNCell(input_size, hidden_size)\n",
        "\n",
        "    pytorch_cell.weight_hh.data = manual_cell.W_hh.data.clone()\n",
        "    pytorch_cell.weight_ih.data = manual_cell.W_ih.data.clone()\n",
        "    pytorch_cell.bias_hh.data = manual_cell.b_hh.data.clone()\n",
        "    pytorch_cell.bias_ih.data = manual_cell.b_ih.data.clone()\n",
        "\n",
        "    # Test input\n",
        "    x = torch.randn(batch_size, input_size)\n",
        "    h = torch.randn(batch_size, hidden_size)\n",
        "\n",
        "    # Forward pass\n",
        "    new_h = manual_cell(x, h)\n",
        "    new_h_pytorch = pytorch_cell(x, h)\n",
        "    max_diff = (new_h_pytorch - new_h).abs().max().item()\n",
        "\n",
        "    # Compare\n",
        "    print(f\"Input shape: {x.shape}\")\n",
        "    print(f\"Hidden shape: {h.shape}\")\n",
        "    print(f\"Output hidden shape: {new_h.shape}\")\n",
        "    # print(f\"Output hidden range: [{new_h.min().item():.3f}, {new_h.max().item():.3f}]\")\n",
        "    print(f\"Max difference: {max_diff:.10f}\")\n",
        "    if max_diff > 1e-6:\n",
        "        print(f\"✗ RNN cell test failed!\")\n",
        "    else:\n",
        "      print(f\"✓ RNN cell test passed!\\n\")\n",
        "\n",
        "\n",
        "def test_rnn():\n",
        "    \"\"\"Test the manual RNN layer\"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Testing RNN Layer\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    input_size, hidden_size, num_layers = 10, 16, 2\n",
        "    batch_size, seq_len = 2, 5\n",
        "\n",
        "    # Create both versions\n",
        "    manual_rnn = ManualRNN(input_size, hidden_size, num_layers)\n",
        "    pytorch_rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    # Copy weights to make them identical\n",
        "    for layer in range(num_layers):\n",
        "        # PyTorch RNN uses different parameter names\n",
        "        pytorch_rnn.__getattr__(f'weight_ih_l{layer}').data = manual_rnn.cells[layer].W_ih.data.clone()\n",
        "        pytorch_rnn.__getattr__(f'weight_hh_l{layer}').data = manual_rnn.cells[layer].W_hh.data.clone()\n",
        "        pytorch_rnn.__getattr__(f'bias_ih_l{layer}').data = manual_rnn.cells[layer].b_ih.data.clone()\n",
        "        pytorch_rnn.__getattr__(f'bias_hh_l{layer}').data = manual_rnn.cells[layer].b_hh.data.clone()\n",
        "\n",
        "    # Test input\n",
        "    x = torch.randn(batch_size, seq_len, input_size)\n",
        "    h = torch.randn(num_layers, batch_size, hidden_size)\n",
        "\n",
        "    # Forward pass\n",
        "    manual_out, manual_h = manual_rnn(x, h)\n",
        "    pytorch_out, pytorch_h = pytorch_rnn(x, h)\n",
        "\n",
        "    o_max_diff = (manual_out - pytorch_out).abs().max().item()\n",
        "    h_max_diff = (manual_h - pytorch_h).abs().max().item()\n",
        "\n",
        "    # Compare\n",
        "    print(f\"Input shape: {x.shape}\")\n",
        "    print(f\"Output shape: {manual_out.shape}\")\n",
        "    print(f\"Hidden shape: {manual_h.shape}\")\n",
        "    print(f\"Output max difference: {o_max_diff:.10f}\")\n",
        "    print(f\"Hidden max difference: {h_max_diff:.10f}\")\n",
        "    if o_max_diff > 1e-6 or h_max_diff > 1e-6:\n",
        "      print(f\"✗ RNN layer test failed!\")\n",
        "    else:\n",
        "      print(f\"✓ RNN layer test passed!\\n\")\n",
        "\n",
        "\n",
        "def test_full_model():\n",
        "    \"\"\"Test the complete CharRNN model\"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Testing Complete CharRNN Model\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    vocab_size = 50\n",
        "    embed_dim, hidden_dim, num_layers = 32, 64, 2\n",
        "    batch_size, seq_len = 4, 10\n",
        "\n",
        "    # Create both models\n",
        "    manual_model = ManualCharRNN(vocab_size, embed_dim, hidden_dim, num_layers)\n",
        "    pytorch_model = CharRNN(vocab_size, embed_dim, hidden_dim, num_layers)\n",
        "\n",
        "    # Copy weights to make them identical\n",
        "    # Embedding\n",
        "    pytorch_model.embedding.weight.data = manual_model.embedding.weight.data.clone()\n",
        "\n",
        "    # RNN layers\n",
        "    for layer in range(num_layers):\n",
        "        pytorch_model.rnn.__getattr__(f'weight_ih_l{layer}').data = manual_model.rnn.cells[layer].W_ih.data.clone()\n",
        "        pytorch_model.rnn.__getattr__(f'weight_hh_l{layer}').data = manual_model.rnn.cells[layer].W_hh.data.clone()\n",
        "        pytorch_model.rnn.__getattr__(f'bias_ih_l{layer}').data = manual_model.rnn.cells[layer].b_ih.data.clone()\n",
        "        pytorch_model.rnn.__getattr__(f'bias_hh_l{layer}').data = manual_model.rnn.cells[layer].b_hh.data.clone()\n",
        "\n",
        "    # Linear layer\n",
        "    pytorch_model.fc.weight.data = manual_model.fc.weight.data.clone()\n",
        "    pytorch_model.fc.bias.data = manual_model.fc.bias.data.clone()\n",
        "\n",
        "    # Test input\n",
        "    x = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
        "    h = torch.randn(num_layers, batch_size, hidden_dim)\n",
        "\n",
        "    # Forward pass\n",
        "    manual_logits, manual_h = manual_model(x, h)\n",
        "    pytorch_logits, pytorch_h = pytorch_model(x, h)\n",
        "\n",
        "    o_max_diff = (manual_logits - pytorch_logits).abs().max().item()\n",
        "    h_max_diff = (manual_h - pytorch_h).abs().max().item()\n",
        "\n",
        "    # Compare\n",
        "    print(f\"Input shape: {x.shape}\")\n",
        "    print(f\"Logits shape: {manual_logits.shape}\")\n",
        "    print(f\"Hidden shape: {manual_h.shape}\")\n",
        "    print(f\"Logits max difference: {o_max_diff:.10f}\")\n",
        "    print(f\"Hidden max difference: {h_max_diff:.10f}\")\n",
        "\n",
        "    # Test if they produce similar predictions\n",
        "    manual_preds = manual_logits.argmax(dim=-1)\n",
        "    pytorch_preds = pytorch_logits.argmax(dim=-1)\n",
        "    agreement = (manual_preds == pytorch_preds).float().mean().item()\n",
        "    print(f\"Prediction agreement: {agreement * 100:.1f}%\")\n",
        "\n",
        "    if o_max_diff > 1e-6 or h_max_diff > 1e-6 or agreement < 0.:\n",
        "      print(f\"✗ Full model test failed!\")\n",
        "    else:\n",
        "      print(f\"✓ Full model test passed!\\n\")"
      ],
      "metadata": {
        "id": "gq45EhKaWBdv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)  # For reproducibility\n",
        "\n",
        "test_embedding()\n",
        "test_rnn_cell()\n",
        "test_rnn()\n",
        "test_full_model()"
      ],
      "metadata": {
        "id": "ETu2pkyY3bYP",
        "outputId": "dac3dc63-14b2-4aa5-ab97-2b1b37fd57f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Testing Embedding Layer\n",
            "======================================================================\n",
            "Input shape: torch.Size([2, 5])\n",
            "Output shape: torch.Size([2, 5, 8])\n",
            "Max difference: 0.0000000000\n",
            "✓ Embedding layer test passed!\n",
            "\n",
            "======================================================================\n",
            "Testing RNN Cell\n",
            "======================================================================\n",
            "Input shape: torch.Size([2, 10])\n",
            "Hidden shape: torch.Size([2, 16])\n",
            "Output hidden shape: torch.Size([2, 16])\n",
            "Max difference: 0.0000000000\n",
            "✓ RNN cell test passed!\n",
            "\n",
            "======================================================================\n",
            "Testing RNN Layer\n",
            "======================================================================\n",
            "Input shape: torch.Size([2, 5, 10])\n",
            "Output shape: torch.Size([2, 5, 16])\n",
            "Hidden shape: torch.Size([2, 2, 16])\n",
            "Output max difference: 0.0000002831\n",
            "Hidden max difference: 0.0000002086\n",
            "✓ RNN layer test passed!\n",
            "\n",
            "======================================================================\n",
            "Testing Complete CharRNN Model\n",
            "======================================================================\n",
            "Input shape: torch.Size([4, 10])\n",
            "Logits shape: torch.Size([4, 10, 50])\n",
            "Hidden shape: torch.Size([2, 4, 64])\n",
            "Logits max difference: 0.0000000000\n",
            "Hidden max difference: 0.0000000000\n",
            "Prediction agreement: 100.0%\n",
            "✓ Full model test passed!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-2 Bidirectional RNN\n",
        "\n",
        "In this second part of the lab, we will train an RNN to solve a task that is different from language modeling. Specifically, for each character in the sequence, we will be predicting the distance to the closest \" \" character, or the start of the sequence. For example:\n",
        "\n",
        "```\n",
        "x: er call'd Elizabeth,\\nVirtuous an\n",
        "y: 110123321012345678910987654321011\n",
        "```\n",
        "and\n",
        "```\n",
        "x: out blemish. Next, it imports no\n",
        "y: 12101234432101232101101234321011\n",
        "```\n",
        "\n",
        "Note that the label is always `0` for the spaces, and otherwise it counts the distance to the closest space, or the start / end of string. We implement this labeling function for you, so the main thing for now is to understand intutively what it is doing\n",
        "\n",
        "### Prepare Data"
      ],
      "metadata": {
        "id": "Bni-Wa9mbQhE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wDHnzJ-a9_y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import requests\n",
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "input_file_path = 'input.txt'\n",
        "data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "with open(input_file_path, 'w') as f:\n",
        "    f.write(requests.get(data_url).text)\n",
        "\n",
        "with open(input_file_path, 'r') as f:\n",
        "    data = f.read()\n",
        "print(f\"length of dataset in characters: {len(data):,}\")\n",
        "\n",
        "# get all the unique characters that occur in this text\n",
        "chars = sorted(list(set(data)))\n",
        "vocab_size = len(chars)\n",
        "print(\"all the unique characters:\", ''.join(chars))\n",
        "print(f\"vocab size: {vocab_size:,}\")\n",
        "\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "def encode(s):\n",
        "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "def decode(l):\n",
        "    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "\n",
        "s = \"machine learning!\"\n",
        "tokens = encode(s)\n",
        "print(f\"{tokens=}\")\n",
        "print(f\"{decode(tokens)=}\")\n",
        "\n",
        "# create the train and test splits\n",
        "n = len(data)\n",
        "train_data = data[:int(n*0.9)]\n",
        "val_data = data[int(n*0.9):]\n",
        "\n",
        "# encode both to integers\n",
        "train_ids = encode(train_data)\n",
        "val_ids = encode(val_data)\n",
        "print(f\"train has {len(train_ids):,} tokens\")\n",
        "print(f\"val has {len(val_ids):,} tokens\")\n",
        "\n",
        "# export to bin files\n",
        "train_ids = np.array(train_ids, dtype=np.uint16)\n",
        "val_ids = np.array(val_ids, dtype=np.uint16)\n",
        "train_ids.tofile('train.bin')\n",
        "val_ids.tofile('val.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the labeling function and the function to generate a batch of data."
      ],
      "metadata": {
        "id": "U5RvW-DUQQXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_fn(x: list[int]) -> list[int]:\n",
        "    \"\"\"\n",
        "    For each position, return the distance to the nearest word boundary.\n",
        "    Word boundaries are spaces (token 1) or sequence edges.\n",
        "    \"\"\"\n",
        "    n = len(x)\n",
        "    labels = []\n",
        "\n",
        "    for i in range(n):\n",
        "        if x[i] == 1:  # space character\n",
        "            labels.append(0)\n",
        "        else:\n",
        "            # Distance to left boundary (space or start of sequence)\n",
        "            left_dist = i + 1  # default: distance to start\n",
        "            for j in range(i - 1, -1, -1):\n",
        "                if x[j] == 1:\n",
        "                    left_dist = i - j\n",
        "                    break\n",
        "\n",
        "            # Distance to right boundary (space or end of sequence)\n",
        "            right_dist = n - i  # default: distance to end\n",
        "            for j in range(i + 1, n):\n",
        "                if x[j] == 1:\n",
        "                    right_dist = j - i\n",
        "                    break\n",
        "\n",
        "            labels.append(min(left_dist, right_dist))\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "def get_batch(split, batch_size = 64, block_size = 256, device=torch.device(\"cpu\")):\n",
        "    # We recreate np.memmap every batch to avoid a memory leak, as per\n",
        "    # https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122\n",
        "    if split == 'train':\n",
        "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
        "    else:\n",
        "        data = np.memmap('val.bin', dtype=np.uint16, mode='r')\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
        "    y = torch.stack([torch.from_numpy(np.array(label_fn(data[i:i+block_size])).astype(np.int64)) for i in ix])\n",
        "    if 'cuda' in device.__str__():\n",
        "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
        "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
        "    else:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "x, y = get_batch('train', batch_size=1, block_size=32)\n",
        "\n",
        "print(f\"{x=}\")\n",
        "print(f\"{y=}\")\n",
        "print(\"~\"*20)\n",
        "print(f\"{decode(x[0].tolist())}\")\n",
        "print(\"\".join(str(s) for s in y[0].tolist()))"
      ],
      "metadata": {
        "id": "LRTx2QghdRr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the labels `y` are the same as the inputs `x`, but shifted by one position. That is because we are predicting the next character at each position."
      ],
      "metadata": {
        "id": "3n7QFSptni0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN Architecture and training\n",
        "\n",
        "Now that we aren't solving a language modeling task, we will need to modify the unembedding layer of our model.\n",
        "\n",
        "**Task:** look at the model and training code below, and explain how our model is different from the RNN for language modeling that we discussed in class, and explain why.\n",
        "\n",
        "**Explanation:** _add your explanation here_"
      ],
      "metadata": {
        "id": "Ytrt0AYro7-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "wOb5JnZbpNgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRegressionRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_layers=2):\n",
        "        \"\"\"\n",
        "        Character-level RNN for language modeling\n",
        "\n",
        "        Args:\n",
        "            vocab_size: Number of unique characters in vocabulary\n",
        "            embed_dim: Dimension of character embeddings\n",
        "            hidden_dim: Dimension of RNN hidden state\n",
        "            num_layers: Number of stacked RNN layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Character embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        # RNN layer (you can swap with LSTM or GRU)\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=embed_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,  # Input shape: (batch, seq, feature)\n",
        "            dropout=0\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch_size, seq_length)\n",
        "            hidden: Optional hidden state from previous step\n",
        "\n",
        "        Returns:\n",
        "            logits: Predicted logits of shape (batch_size, seq_length, vocab_size)\n",
        "            hidden: Hidden state for next step\n",
        "        \"\"\"\n",
        "        # Embed characters: (batch, seq) -> (batch, seq, embed_dim)\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Pass through RNN: (batch, seq, embed_dim) -> (batch, seq, hidden_dim)\n",
        "        rnn_out, hidden = self.rnn(embedded, hidden)\n",
        "\n",
        "        # Project to vocabulary: (batch, seq, hidden_dim) -> (batch, seq, vocab_size)\n",
        "        logits = self.fc(rnn_out)\n",
        "\n",
        "        return logits, hidden"
      ],
      "metadata": {
        "id": "MI56T1WXnZHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do 10 epochs on the data"
      ],
      "metadata": {
        "id": "FJOfuZcrtgaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 65\n",
        "embed_dim = 128\n",
        "hidden_dim = 128\n",
        "num_layers = 1\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "total_tokens = 10_000_000 # 1_000_000\n",
        "batch_size = 64\n",
        "block_size = 256\n",
        "total_steps = total_tokens // (batch_size * block_size)\n",
        "print(f\"Total steps: {total_steps:,}\")\n",
        "\n",
        "model = CharRegressionRNN(vocab_size, embed_dim, hidden_dim, num_layers).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.e-3)\n",
        "model.train()\n",
        "\n",
        "losses = []\n",
        "tokens_done_lst = []\n",
        "tokens_done = 0\n",
        "\n",
        "pbar = tqdm.tqdm(range(total_steps))\n",
        "for step in pbar:\n",
        "  # Get batch\n",
        "  x, y = get_batch('train', batch_size, block_size, device=device)\n",
        "  optimizer.zero_grad()\n",
        "  predictions, _ = model(x)\n",
        "  predictions = predictions.reshape(-1)\n",
        "  y = y.reshape(-1).float()\n",
        "\n",
        "  # Compute loss and backprop\n",
        "  loss = criterion(predictions, y)\n",
        "  loss.backward()\n",
        "\n",
        "  losses.append(loss.item())\n",
        "  tokens_done += x.numel()\n",
        "  tokens_done_lst.append(tokens_done)\n",
        "\n",
        "  pbar.set_description(f\"Loss: {loss.item():.4f}\\tTokens: {tokens_done}\\tProgress\")\n",
        "\n",
        "  # Gradient clipping (helpful for RNNs)\n",
        "  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "  optimizer.step()\n"
      ],
      "metadata": {
        "id": "L178Fxy-qycb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tokens_done_lst, losses)\n",
        "plt.xscale(\"log\")\n",
        "plt.grid()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"tokens trained on\")"
      ],
      "metadata": {
        "id": "CqfgwnDtpMQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = \" sad sadness happy happiness \"\n",
        "# s = \"Here is a long word: unhappy\"\n",
        "x = torch.from_numpy(np.array(encode(s)))\n",
        "y = label_fn(encode(s))\n",
        "preds = model(x)[0].detach()\n",
        "print(y)\n",
        "print([f\"{p.item():.1f}\" for p in preds])\n",
        "\n",
        "plt.plot(y, \"-b\", label=\"true label\")\n",
        "plt.plot(preds, \"--r\", label=\"prediction\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.xlabel(\"token id\")"
      ],
      "metadata": {
        "id": "B93vRndzTOzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task**: You can see that our model is not perfect at the task. Why do you think that is?\n",
        "\n",
        "**Explanation:** _add your explanation here_"
      ],
      "metadata": {
        "id": "XlY8MhJTUlPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bidirectional model\n",
        "\n",
        "Now, let's make a bidirectional RNN for this task. Complete the code below to make a bidirectional RNN."
      ],
      "metadata": {
        "id": "-dNjRElwU8-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRegressionBiRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_layers=2):\n",
        "        \"\"\"\n",
        "        Character-level RNN for language modeling\n",
        "\n",
        "        Args:\n",
        "            vocab_size: Number of unique characters in vocabulary\n",
        "            embed_dim: Dimension of character embeddings\n",
        "            hidden_dim: Dimension of RNN hidden state\n",
        "            num_layers: Number of stacked RNN layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Character embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        # RNN layer (you can swap with LSTM or GRU)\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=embed_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,  # Input shape: (batch, seq, feature)\n",
        "            dropout=0,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch_size, seq_length)\n",
        "            hidden: Optional hidden state from previous step\n",
        "\n",
        "        Returns:\n",
        "            logits: Predicted logits of shape (batch_size, seq_length, vocab_size)\n",
        "            hidden: Hidden state for next step\n",
        "        \"\"\"\n",
        "        # Embed characters: (batch, seq) -> (batch, seq, embed_dim)\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Pass through RNN: (batch, seq, embed_dim) -> (batch, seq, hidden_dim)\n",
        "        rnn_out, hidden = self.rnn(embedded, hidden)\n",
        "\n",
        "        # Project to vocabulary: (batch, seq, hidden_dim) -> (batch, seq, vocab_size)\n",
        "        logits = self.fc(rnn_out)\n",
        "\n",
        "        return logits, hidden"
      ],
      "metadata": {
        "id": "EpofM09jU7X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 65\n",
        "embed_dim = 128\n",
        "hidden_dim = 128\n",
        "num_layers = 1\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "total_tokens = 10_000_000 # 1_000_000\n",
        "batch_size = 64\n",
        "block_size = 256\n",
        "total_steps = total_tokens // (batch_size * block_size)\n",
        "print(f\"Total steps: {total_steps:,}\")\n",
        "\n",
        "model = CharRegressionBiRNN(vocab_size, embed_dim, hidden_dim, num_layers).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.e-3)\n",
        "model.train()\n",
        "\n",
        "losses = []\n",
        "tokens_done_lst = []\n",
        "tokens_done = 0\n",
        "\n",
        "pbar = tqdm.tqdm(range(total_steps))\n",
        "for step in pbar:\n",
        "  # Get batch\n",
        "  x, y = get_batch('train', batch_size, block_size, device=device)\n",
        "  optimizer.zero_grad()\n",
        "  predictions, _ = model(x)\n",
        "  predictions = predictions.reshape(-1)\n",
        "  y = y.reshape(-1).float()\n",
        "\n",
        "  # Compute loss and backprop\n",
        "  loss = criterion(predictions, y)\n",
        "  loss.backward()\n",
        "\n",
        "  losses.append(loss.item())\n",
        "  tokens_done += x.numel()\n",
        "  tokens_done_lst.append(tokens_done)\n",
        "\n",
        "  pbar.set_description(f\"Loss: {loss.item():.4f}\\tTokens: {tokens_done}\\tProgress\")\n",
        "\n",
        "  # Gradient clipping (helpful for RNNs)\n",
        "  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "  optimizer.step()\n"
      ],
      "metadata": {
        "id": "JSApFDYfVtbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tokens_done_lst, losses)\n",
        "plt.xscale(\"log\")\n",
        "plt.grid()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"tokens trained on\")"
      ],
      "metadata": {
        "id": "zokjNi-8WsPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = \" sad sadness happy happiness \"\n",
        "x = torch.from_numpy(np.array(encode(s)))\n",
        "y = label_fn(encode(s))\n",
        "preds = model(x)[0].detach()\n",
        "print(y)\n",
        "print([f\"{p.item():.1f}\" for p in preds])\n",
        "\n",
        "plt.plot(y, \"-b\", label=\"true label\")\n",
        "plt.plot(preds, \"--r\", label=\"prediction\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.xlabel(\"token id\")"
      ],
      "metadata": {
        "id": "J0O_Vbj-WsPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Compare the loss values and the prediction quality to the one-directional model we trained above. Explain your observations.\n",
        "\n",
        "**Explanation:** _add your explanation here_"
      ],
      "metadata": {
        "id": "sycWt3t4Wva4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IHe6tVemd2Jp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}